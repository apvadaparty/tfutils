"""
This script contains function `dataset_func` which will return dataset elements

The data format structure of ImageNet required for `dataset_func` is similar as
data structure generated by following structure:
    https://github.com/tensorflow/models/blob/master/research/inception/inception/data/build_imagenet_data.py

The only difference is that each tfrecords file only contains two attributes:
    images: jpeg format of images
    labels: int64 of 0-999 labels
"""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tensorflow as tf

import os, sys
import numpy as np
import pdb


def get_tfr_filenames(folder_name, file_pattern='train-*'):
    """
    Get list of tfrecord filenames
    for given folder_name fitting the given file_pattern
    """
    tfrecord_pattern = os.path.join(folder_name, file_pattern)
    datasource = tf.gfile.Glob(tfrecord_pattern)
    datasource.sort()
    return np.asarray(datasource)


def fetch_dataset(filename):
    """
    Useful util function for fetching records
    """
    buffer_size = 32 * 1024 * 1024     # 32 MiB per file
    dataset = tf.data.TFRecordDataset(filename, buffer_size=buffer_size)
    return dataset


def data_paser(
        value, is_train=True,
        ):
    """
    Parse record and preprocessing
    """
    # Load the image and preprocess it
    keys_to_features = {
            'images': tf.FixedLenFeature((), tf.string, ''),
            'labels': tf.FixedLenFeature([], tf.int64, -1)}
    parsed = tf.parse_single_example(value, keys_to_features)
    image_string = parsed['images']
    image_label = parsed['labels']
    image_index = parsed.get('index', None)

    # Do the preprocessing
    crop_size = 224
    image = preprocessing(
            image_string,
            crop_size,
            crop_size,
            is_train,
            )
    ret_dict = {
            'images':image,
            'labels':image_label}
    return ret_dict


def get_resize_scale(height, width, smallest_side):
    """
    Get the resize scale so that the shortest side is `smallest_side`
    """
    smallest_side = tf.convert_to_tensor(smallest_side, dtype=tf.int32)

    height = tf.to_float(height)
    width = tf.to_float(width)
    smallest_side = tf.to_float(smallest_side)

    scale = tf.cond(
            tf.greater(height, width),
            lambda: smallest_side / width,
            lambda: smallest_side / height)
    return scale


def _at_least_x_are_true(a, b, x):
  """At least `x` of `a` and `b` `Tensors` are true."""
  match = tf.equal(a, b)
  match = tf.cast(match, tf.int32)
  return tf.greater_equal(tf.reduce_sum(match), x)


def RandomSizedCrop_from_jpeg(
        image_str, 
        out_height, 
        out_width, 
        size_minval=0.08,
        ):
    """
    Random crop in Inception style, see GoogLeNet paper
    """
    shape = tf.image.extract_jpeg_shape(image_str)
    bbox = tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])
    crop_max_attempts = 100
    sample_distorted_bounding_box = tf.image.sample_distorted_bounding_box(
            shape,
            bounding_boxes=bbox,
            min_object_covered=0.1,
            aspect_ratio_range=(3. / 4, 4. / 3.),
            area_range=(size_minval, 1.0),
            max_attempts=crop_max_attempts,
            use_image_if_no_bounding_boxes=True)
    bbox_begin, bbox_size, bbox = sample_distorted_bounding_box
    random_image = tf.image.decode_and_crop_jpeg(
            image_str, 
            tf.stack([bbox_begin[0], bbox_begin[1], \
                      bbox_size[0], bbox_size[1]]),
            channels=3)
    bad = _at_least_x_are_true(shape, tf.shape(random_image), 3)
    # central crop if bad
    min_size = tf.minimum(shape[0], shape[1])
    offset_height = tf.random_uniform(
            shape=[],
            minval=0, maxval=shape[0] - min_size + 1,
            dtype=tf.int32
            )
    offset_width = tf.random_uniform(
            shape=[],
            minval=0, maxval=shape[1] - min_size + 1,
            dtype=tf.int32
            )
    bad_image = tf.image.decode_and_crop_jpeg(
            image_str, 
            tf.stack([offset_height, offset_width, \
                      min_size, min_size]),
            channels=3)
    image = tf.cond(
            bad, 
            lambda: bad_image,
            lambda: random_image,
            )
    # if use py_func, will do resize elsewhere
    image = tf.cast(
            tf.image.resize_bilinear(
                [image], 
                [out_height, out_width])[0],
            dtype=tf.uint8)
    image.set_shape([out_height, out_width, 3])
    return image


def color_normalize(image):
    image = tf.cast(image, tf.float32) / 255
    imagenet_mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)
    imagenet_std = np.array([0.229, 0.224, 0.225], dtype=np.float32)
    image = (image - imagenet_mean) / imagenet_std
    return image


def preprocessing(
        image_string,
        out_height,
        out_width,
        is_train,
        ):
    """
    Preprocessing for each image
    """
    def _val_func(image_string):
        shape = tf.image.extract_jpeg_shape(image_string)
        scale = get_resize_scale(shape[0], shape[1], 256)
        cp_height = tf.cast(out_height / scale, tf.int32)
        cp_width = tf.cast(out_width / scale, tf.int32)
        cp_begin_x = tf.cast((shape[0] - cp_height) / 2, tf.int32)
        cp_begin_y = tf.cast((shape[1] - cp_width) / 2, tf.int32)
        bbox = tf.stack([
                cp_begin_x, cp_begin_y, \
                cp_height, cp_width])
        crop_image = tf.image.decode_and_crop_jpeg(
                image_string, 
                bbox,
                channels=3)
        image = tf.cast(
                tf.image.resize_bilinear(
                    [crop_image], 
                    [out_height, out_width])[0],
                dtype=tf.uint8)

        image.set_shape([out_height, out_width, 3])
        return image

    def _rand_crop(image_string):
        image = RandomSizedCrop_from_jpeg(
                image_string,
                out_height=out_height,
                out_width=out_width,
                )
        return image

    if is_train:
        image = _rand_crop(image_string)
        image = tf.image.random_flip_left_right(image)

    else:
        image = _val_func(image_string)

    image = color_normalize(image)
    return image


def dataset_func(image_dir, is_train, batch_size, q_cap=51200):
    """
    Build the dataset, get the elements
    """
    # First get tfrecords names
    tfr_params = {}
    if not is_train:
        tfr_params['file_pattern'] = 'validation-*'
    tfr_list = get_tfr_filenames(image_dir, **tfr_params)

    # Build list_file dataset from tfrecord files
    dataset = tf.data.Dataset.list_files(tfr_list)
    if is_train:
        dataset = dataset.apply(
                tf.contrib.data.shuffle_and_repeat(
                    len(tfr_list)))
    else:
        dataset = dataset.repeat()

    # Read each file
    dataset = dataset.apply(
            tf.contrib.data.parallel_interleave(
               fetch_dataset, cycle_length=8, sloppy=True))

    # Shuffle and preprocessing
    if is_train:
        dataset = dataset.shuffle(buffer_size=q_cap)
    dataset = dataset.prefetch(batch_size * 4)
    dataset = dataset.map(
            lambda x: data_paser(
                x, is_train),
            num_parallel_calls=64)

    # Batch the dataset and make iteratior
    dataset = dataset.apply(
        tf.contrib.data.batch_and_drop_remainder(batch_size))
    dataset = dataset.prefetch(4)
    next_element = dataset.make_one_shot_iterator().get_next()
    return next_element
